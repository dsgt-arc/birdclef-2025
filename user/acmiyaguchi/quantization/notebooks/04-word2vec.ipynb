{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38e12562",
   "metadata": {},
   "source": [
    "In this notebook we're going to paramterize a word2vec model with tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e086886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/storage/home/hcoda1/8/amiyaguchi3/scratch/birdclef/2025/mel2vec\u001b[0m\n",
      "├── \u001b[01;34mtokenizer\u001b[0m\n",
      "│   └── centroids.npy\n",
      "└── \u001b[01;34mtokenizer_pca\u001b[0m\n",
      "    ├── centroids.npy\n",
      "    └── pca.bin\n",
      "\n",
      "2 directories, 3 files\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "scratch = Path(\"~/scratch/birdclef/2025\").expanduser()\n",
    "! tree {scratch}/mel2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbb7dce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "# load the tokenizer\n",
    "centroids = np.load(f\"{scratch}/mel2vec/tokenizer/centroids.npy\")\n",
    "index = faiss.IndexFlatL2(centroids.shape[1])\n",
    "index.add(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>NAIVE QUERY PLAN</h4><p>run <b>LazyFrame.show_graph()</b> to see the optimized version</p><?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.44.0 (0)\n",
       " -->\n",
       "<!-- Title: polars_query Pages: 1 -->\n",
       "<svg width=\"1160pt\" height=\"262pt\"\n",
       " viewBox=\"0.00 0.00 1160.00 262.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 258)\">\n",
       "<title>polars_query</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-258 1156,-258 1156,4 -4,4\"/>\n",
       "<!-- p1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>p1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"693,-254 459,-254 459,-218 693,-218 693,-254\"/>\n",
       "<text text-anchor=\"middle\" x=\"576\" y=\"-232.3\" font-family=\"Times-Roman\" font-size=\"14.00\">WITH COLUMNS [Series[token]]</text>\n",
       "</g>\n",
       "<!-- p2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>p2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"717,-182 435,-182 435,-146 717,-146 717,-182\"/>\n",
       "<text text-anchor=\"middle\" x=\"576\" y=\"-160.3\" font-family=\"Times-Roman\" font-size=\"14.00\">SORT BY [col(&quot;file&quot;), col(&quot;timestamp&quot;)]</text>\n",
       "</g>\n",
       "<!-- p1&#45;&#45;p2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>p1&#45;&#45;p2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M576,-217.7C576,-206.85 576,-192.92 576,-182.1\"/>\n",
       "</g>\n",
       "<!-- p3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>p3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"691.5,-110 460.5,-110 460.5,-74 691.5,-74 691.5,-110\"/>\n",
       "<text text-anchor=\"middle\" x=\"576\" y=\"-88.3\" font-family=\"Times-Roman\" font-size=\"14.00\">FILTER BY [(col(&quot;part&quot;)) &lt; (80)]</text>\n",
       "</g>\n",
       "<!-- p2&#45;&#45;p3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>p2&#45;&#45;p3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M576,-145.7C576,-134.85 576,-120.92 576,-110.1\"/>\n",
       "</g>\n",
       "<!-- p4 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>p4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1152,-38 0,-38 0,0 1152,0 1152,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"576\" y=\"-22.8\" font-family=\"Times-Roman\" font-size=\"14.00\">Parquet SCAN [/storage/home/hcoda1/8/amiyaguchi3/scratch/birdclef/2025/mfcc&#45;soundscape/data/part=0/H02_20230420_074000.parquet, ... 9725 other sources]</text>\n",
       "<text text-anchor=\"middle\" x=\"576\" y=\"-7.8\" font-family=\"Times-Roman\" font-size=\"14.00\">π */5;</text>\n",
       "</g>\n",
       "<!-- p3&#45;&#45;p4 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>p3&#45;&#45;p4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M576,-73.81C576,-62.98 576,-49.01 576,-38.02\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<LazyFrame at 0x7FFE5E8955A0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we load the dataset, learning word2vec only on 80% of the data\n",
    "df = (\n",
    "    pl.scan_parquet(f\"{scratch}/mfcc-soundscape/data\")\n",
    "    .filter(pl.col(\"part\") < 80)\n",
    "    .sort(\"file\", \"timestamp\")\n",
    ")\n",
    "X = np.stack(df.select(\"mfcc\").collect().get_column(\"mfcc\").to_numpy())\n",
    "_, indices = index.search(X, 1)\n",
    "ids = pl.Series(\"token\", indices.flatten())\n",
    "token_df = df.with_columns(ids)\n",
    "token_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a25a09a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "\n",
    "class TqdmCallback(CallbackAny2Vec):\n",
    "    def __init__(self, total_epochs):\n",
    "        self.total_epochs = total_epochs\n",
    "        self.epoch_count = 0\n",
    "        self.pbar = None\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        if self.pbar is None:\n",
    "            self.pbar = tqdm(total=self.total_epochs, desc=\"Epochs\")\n",
    "        self.epoch_count += 1\n",
    "        self.pbar.set_description(\n",
    "            f\"Training Epoch {self.epoch_count}/{self.total_epochs}\"\n",
    "        )\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        if self.pbar is not None:\n",
    "            self.pbar.update(1)\n",
    "        current_loss = model.get_latest_training_loss()\n",
    "        if current_loss is not None:\n",
    "            self.pbar.set_postfix_str(f\"Loss: {current_loss:.4f}\", refresh=True)\n",
    "\n",
    "    def on_train_end(self, model):\n",
    "        if self.pbar is not None:\n",
    "            self.pbar.close()\n",
    "            self.pbar = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec337fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf39f1e76a845f996d4963d07e77715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "# group by file, order by timestamp, and collect the tokens\n",
    "def token_generator(df, limit=-1):\n",
    "    if limit > 0:\n",
    "        df = df.filter(pl.col(\"part\") < limit)\n",
    "    for sub in df.collect().partition_by(\"file\"):\n",
    "        yield sub.sort(\"timestamp\").get_column(\"token\").to_list()\n",
    "\n",
    "\n",
    "model = Word2Vec(\n",
    "    sentences=list(token_generator(token_df, limit=10)),\n",
    "    vector_size=128,\n",
    "    # 5 seconds, 8 frames per second = 40\n",
    "    # can go to 10 seconds to have more context\n",
    "    min_count=1,\n",
    "    window=80,\n",
    "    sg=1,\n",
    "    negative=10,\n",
    "    ns_exponent=0.75,\n",
    "    sample=1e-3,\n",
    "    workers=8,\n",
    "    compute_loss=True,\n",
    "    shrink_windows=True,\n",
    "    epochs=5,\n",
    "    callbacks=[TqdmCallback(total_epochs=5)],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
