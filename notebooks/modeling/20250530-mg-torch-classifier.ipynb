{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f824b27",
   "metadata": {},
   "source": [
    "# PyTorch Lightning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09f81754",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a9f0955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (11037, 2)\n",
      "Embedding size: 1280\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species_name</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amakin1</td>\n",
       "      <td>[-0.026628008112311363, 0.07033359259366989, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amekes</td>\n",
       "      <td>[0.09562845528125763, 0.004033610224723816, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amekes</td>\n",
       "      <td>[0.11211416870355606, -0.0019105728715658188, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amekes</td>\n",
       "      <td>[0.09912332147359848, -0.030860736966133118, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amekes</td>\n",
       "      <td>[0.0636802390217781, 0.01985364407300949, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species_name                                         embeddings\n",
       "0      amakin1  [-0.026628008112311363, 0.07033359259366989, 0...\n",
       "1       amekes  [0.09562845528125763, 0.004033610224723816, 0....\n",
       "2       amekes  [0.11211416870355606, -0.0019105728715658188, ...\n",
       "3       amekes  [0.09912332147359848, -0.030860736966133118, 0...\n",
       "4       amekes  [0.0636802390217781, 0.01985364407300949, -0.0..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "scratch_dir = \"~/scratch/birdclef/data/2025\"\n",
    "model_name = \"Perch\"\n",
    "embed_dir = (\n",
    "    f\"{scratch_dir}/subset-train_audio-infer-soundscape-cpu/{model_name}/parts/embed/\"\n",
    ")\n",
    "\n",
    "\n",
    "def preprocess_data(input_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_parquet(input_path)\n",
    "    # concatenate all embeddings into a single DataFrame\n",
    "    df[\"species_name\"] = df[\"file\"].apply(\n",
    "        lambda x: x.split(\"train_audio/\")[1].split(\"/\")[0]\n",
    "    )\n",
    "    # train/test split requries y label to have at least 2 samples\n",
    "    # remove species with less than 2 samples\n",
    "    species_count = df[\"species_name\"].value_counts()\n",
    "    valid_species = species_count[species_count >= 2].index\n",
    "    filtered_df = df[df[\"species_name\"].isin(valid_species)].reset_index(drop=True)\n",
    "    # concatenate embeddings\n",
    "    embed_cols = list(map(str, range(1280)))\n",
    "    filtered_df[\"embeddings\"] = filtered_df[embed_cols].values.tolist()\n",
    "    # downsample for debugging\n",
    "    df_embs = filtered_df[[\"species_name\", \"embeddings\"]].copy()\n",
    "    print(f\"DataFrame shape: {df_embs.shape}\")\n",
    "    print(f\"Embedding size: {len(df_embs['embeddings'].iloc[0])}\")\n",
    "    return df_embs\n",
    "\n",
    "\n",
    "df = preprocess_data(embed_dir)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa5dc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train, X_test shape: ((8829, 1280), (2208, 1280))\n",
      "y_train, y_test shape: ((8829,), (2208,))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def perform_train_test_split(\n",
    "    df: pd.DataFrame, test_size: float = 0.2, random_state: int = 42\n",
    ") -> tuple:\n",
    "    # train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        np.stack(df[\"embeddings\"]),\n",
    "        df[\"species_name\"],\n",
    "        test_size=test_size,\n",
    "        stratify=df[\"species_name\"],\n",
    "    )\n",
    "\n",
    "    # data shape\n",
    "    print(f\"X_train, X_test shape: {X_train.shape, X_test.shape}\")\n",
    "    print(f\"y_train, y_test shape: {y_train.shape, y_test.shape}\")\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# perform train/test split\n",
    "X_train, X_test, y_train, y_test = perform_train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "\n",
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, X, y, label_to_idx):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor([label_to_idx[label] for label in y], dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "class BirdDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, X_train, X_test, y_train, y_test, label_to_idx, batch_size=64):\n",
    "        super().__init__()\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.label_to_idx = label_to_idx\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = BirdDataset(self.X_train, self.y_train, self.label_to_idx)\n",
    "        self.val_dataset = BirdDataset(self.X_test, self.y_test, self.label_to_idx)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
    "\n",
    "\n",
    "class LinearClassifier(pl.LightningModule):\n",
    "    def __init__(self, input_dim, num_classes, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0dc8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/hcoda1/9/mgustineli3/clef/birdclef-2025/.venv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.10 /storage/home/hcoda1/9/mgustineli3/clef/birdclef ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025-05-30 23:39:57.925623: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-30 23:40:08.939736: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-30 23:40:09.613116: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-30 23:40:09.857825: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-30 23:40:11.688789: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-30 23:40:46.554665: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | Sequential       | 661 K  | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "661 K     Trainable params\n",
      "0         Non-trainable params\n",
      "661 K     Total params\n",
      "2.644     Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c30395fafa748b9af4f8f0fdfead55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/hcoda1/9/mgustineli3/clef/birdclef-2025/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=5` in the `DataLoader` to improve performance.\n",
      "/storage/home/hcoda1/9/mgustineli3/clef/birdclef-2025/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=5` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30892db38d64786bfceba38884c0104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fcba80897af474698d60c35998da99c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc791170c7e448ceb08895bc21eee281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a595fcf7cf9b44e5ae8d582bca46d281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648d8d42391c49d0b9da273ce8c7be95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1959b5b58543b5b6dbd891b4b9191f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b20722c3a16426db57814c7afef4f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274178fead93493d808e5007fc664647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d04749ba1c44e68d972b2eb95a7498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa125998d1d04946928bac975e15b196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "# create label index mapping\n",
    "unique_labels = sorted(df[\"species_name\"].unique())\n",
    "label_to_idx = {label: i for i, label in enumerate(unique_labels)}\n",
    "num_classes = len(label_to_idx)\n",
    "\n",
    "# instantiate DataModule\n",
    "data_module = BirdDataModule(X_train, X_test, y_train, y_test, label_to_idx)\n",
    "\n",
    "# instantiate model\n",
    "model = LinearClassifier(input_dim=1280, num_classes=num_classes)\n",
    "\n",
    "# logger and callbacks\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"linear_classifier\")\n",
    "\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "early_stopping_cb = EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n",
    "\n",
    "# trainer\n",
    "trainer = Trainer(\n",
    "    max_epochs=50,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    "    accelerator=\"auto\",\n",
    ")\n",
    "\n",
    "# fit model\n",
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20c76cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3993f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
