{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "459b0780",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30d07ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved compiled model to /storage/home/hcoda1/8/amiyaguchi3/shared/birdclef/models/2025/compiled/Perch_head.onnx\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from birdclef.kaggle.compile import compile_classifier_head, benchmark_perch\n",
    "\n",
    "compile_classifier_head(\n",
    "    \"~/shared/birdclef/models/2025/compiled\",\n",
    "    \"Perch\",\n",
    "    \"~/shared/birdclef/models/2025/v1/Perch/torch-linear-v1/checkpoints/best-checkpoint-Perch-epoch=05-val_loss=0.76.ckpt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59a69ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 204)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load this model and try it out\n",
    "import openvino as ov\n",
    "import numpy as np\n",
    "from birdclef.config import model_config\n",
    "\n",
    "model = ov.compile_model(\n",
    "    Path(\"~/shared/birdclef/models/2025/compiled/Perch_head.onnx\").expanduser(), \"CPU\"\n",
    ")\n",
    "\n",
    "# now run a prediction\n",
    "example_input = np.random.rand(1, model_config[\"Perch\"][\"embed_size\"]).astype(\n",
    "    np.float32\n",
    ")\n",
    "\n",
    "res = model(example_input)\n",
    "res[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "989a0f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 03:34:17.868964: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_inter_op_parallelism which is not in the op definition: Op<name=Transpose; signature=x:T, perm:Tperm -> y:T; attr=T:type; attr=Tperm:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node Transpose}}\n",
      "/storage/home/hcoda1/8/amiyaguchi3/clef/birdclef-2025/.venv/lib/python3.10/site-packages/opensoundscape/ml/cnn.py:599: UserWarning: \n",
      "                    This architecture is not listed in opensoundscape.ml.cnn_architectures.ARCH_DICT.\n",
      "                    It will not be available for loading after saving the model with .save() (unless using pickle=True). \n",
      "                    To make it re-loadable, define a function that generates the architecture from arguments: (n_classes, n_channels) \n",
      "                    then use opensoundscape.ml.cnn_architectures.register_architecture() to register the generating function.\n",
      "\n",
      "                    The function can also set the returned object's .constructor_name to the registered string key in ARCH_DICT\n",
      "                    to avoid this warning and ensure it is reloaded correctly by opensoundscape.ml.load_model().\n",
      "\n",
      "                    See opensoundscape.ml.cnn_architectures module for examples of constructor functions\n",
      "                    \n",
      "  warnings.warn(\n",
      "/storage/home/hcoda1/8/amiyaguchi3/clef/birdclef-2025/.venv/lib/python3.10/site-packages/opensoundscape/ml/cnn.py:623: UserWarning: Failed to detect expected # input channels of this architecture.Make sure your architecture expects the number of channels equal to `channels` argument 1). Pytorch architectures generally expect 3 channels by default.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Perch TFLite model...\n",
      "                                                                            0     ...      1279\n",
      "file                                               start_time end_time            ...          \n",
      "/storage/home/hcoda1/8/amiyaguchi3/scratch/bird... 0.0        5.0      -0.013070  ... -0.033343\n",
      "                                                   5.0        10.0      0.050018  ... -0.031186\n",
      "                                                   10.0       15.0      0.031905  ... -0.055638\n",
      "                                                   15.0       20.0     -0.046089  ... -0.048108\n",
      "                                                   20.0       25.0      0.078878  ... -0.018229\n",
      "\n",
      "[5 rows x 1280 columns]\n",
      "Perch TFLite took 6.54 seconds for 5 files\n",
      "Running classification head\n",
      "Classification head took 0.00 seconds for 5 files\n",
      "OpenVINO classification head took 0.01 seconds for 5 files\n"
     ]
    }
   ],
   "source": [
    "benchmark_perch(\n",
    "    \"~/scratch/birdclef/test_soundscape\",\n",
    "    \"~/shared/birdclef/models/2025/compiled\",\n",
    "    \"~/shared/birdclef/models/2025/v1/Perch/torch-linear-v1/checkpoints/best-checkpoint-Perch-epoch=05-val_loss=0.76.ckpt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c76af6d",
   "metadata": {},
   "source": [
    "Cool, with this we know that the classifier head on top is negligible in speed.\n",
    "We effectively don't need to care about it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
